# digit-recognition
Hi! Welcome to my solution for the ["Machine Learning Institute Foundation Project"](https://programme.mlx.institute/interview/project)  

As requested in the foundation project requirements mentioned above, this has two main modules:
- frontend: provides the UI for drawing the digits, show the predicted results and list of last ten predictions;
- service: loads a pytorch pre-trained model for the digits mnist dataset and uses the model for predicting the images sent by the frontend

Additional to the above modules, this project contains additional folder with utility resources:
- db: contains the init.sql script for creating the table used for saving the predictions;
- model_training: includes a jupyter notebook with the code used for training the model;

The frontend and service models are detailed below:

## frontend
- Uses streamlit to render free canvas drawing for drawing the digits;
- An input texts defining the "true" label of the digit;
- A submit button to send the drawn image to the prediction service;
- Renders the predicted digit and the confidence returned by the prediction service;
- Saves the prediction, true label and generated image to a postgresql database table;
- Lists the last ten predictions saved in the database;
- The db_accessor.py file defines functions related with database access. Is used by the canvas.py file;
- The canvas.py file renders the various UI components using streamlit, submits the drawn image and process the 
response from the service.

## service
- Defines the model class identical to the one used to train the model in the jupyter notebook;
- Loads the pre-trained and saved model using the model class;
- There are a few saved model files, after different hyperparameters tuning experimented in the training phase;
- The digit_model_cv2d-2.pth is being used currently, this reflects the tunings that yielded the best accuracy during the training phase;

## general observations
During this exercise, initial tests with canvas drawn image were having very poor accuracy, 
despite the mnist test dataset performing well. I've suspected this was due to the image generated by the streamlit 
canvas be diverging too much from the ones in the mnist dataset. I could confirm that by sending the preprocessed image
forwarded to the model back in the response to be inspected in the frontend UI. That helped guide the pre-processing 
applied prior to forwarding to the model. With an increase in contrast and inversion, the model started to perform 
better. I decided to save the pre-processed image together with the predicted and user informed true label so that
it could be used to augment the model training in the future.

